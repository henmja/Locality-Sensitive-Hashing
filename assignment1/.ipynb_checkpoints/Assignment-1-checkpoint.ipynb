{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment the goal is to implement the dimensionality reduction technique *Principal Component Analysis (PCA)* to a very high dimensional data and apply visualization. Note that you are not allowed to use the built-in PCA API provided by the sklearn library. Instead you will be implementing from the scratch.\n",
    "\n",
    "    For this task we use the MNIST dataset. First we download the dataset using openml api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', cache=False)\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1: Preprocessing\n",
    "Before implementing PCA you are required to perform some preprocessing steps:\n",
    "1. Mean normalization: Replace each feature/attribute, $x_{ji}$ with $x_j - \\mu_j$, In other words, determine the mean of each feature set, and then for each feature subtract the mean from the value, so we re-scale the mean to be 0 \n",
    "2. Feature scaling: If features have very different scales then scale make them comparable by altering the scale, so they all have a comparable range of values e.g. $x_{ji}$ is set to $(x_j - \\mu_j) / s_j$  Where $s_j$ is some measure of the range, so could be  $\\max(x_j) - \\min(x_j)$ or Standard deviation $stddev(x_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n",
      "(70000,)\n",
      "[[-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " ...\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]]\n",
      "[[-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " ...\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]]\n"
     ]
    }
   ],
   "source": [
    "#TODO Implement mean normalization and feature scaling\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#transpose X:\n",
    "Xt = np.transpose(X)\n",
    "# Average of the values in each row of X\n",
    "ave_rows = np.mean(Xt, axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each row of X\n",
    "std_rows = Xt.std(axis=0)    \n",
    "\n",
    "#should be same number of rows as in X.shape:\n",
    "# Print the shape of ave_rows\n",
    "print(ave_rows.shape)\n",
    "# Print the shape of std_rows\n",
    "print(std_rows.shape)\n",
    "\n",
    "#Mean normalization of X\n",
    "X_norm = (Xt - ave_rows)\n",
    "\n",
    "#Feature Scaling of X\n",
    "X_scaled = X_norm/std_rows\n",
    "\n",
    "print(X_norm)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2: Covariance matrix\n",
    "Now the preprocessing is finished. Next, as explained in the lecture, you need to compute the covariance matrix https://en.wikipedia.org/wiki/Covariance_matrix. Given $n \\times m$ $n$ rows and $m$ columns matrix, a covariance matrix is an $n \\times n$ matrix given as below (sigma)\n",
    "$\\Sigma = \\frac{1}{m}\\sum{\\left(x^{i}\\right)\\times \\left(x^{i}\\right)^{T}}$\n",
    "You may use the \"numpy.cov\" function in numpy library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " ...\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]]\n"
     ]
    }
   ],
   "source": [
    "#TODO Compute X to covariance matrix cov_matrix.\n",
    "cov_matrix = np.cov(X_scaled)\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-3: SVD computation\n",
    "Now compute the SVD on the covariance matrix $SVD(\\Sigma)$. You may use the svd implementation in numpy.linalg.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def getSVD(temp):\n",
    "    U, S, V = np.linalg.svd(temp,  full_matrices=False)\n",
    "    return (U,S,V)\n",
    "U,S,V = getSVD(cov_matrix) #SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-4: Compute PCA matrix (K dimensional)\n",
    "Now select the first $k$ columns from the matrix $U$ and multiply with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKComponents(U, X, K):\n",
    "    #TODO implement matrix multiplication of first k columns of U * X\n",
    "    Uk = np.transpose(U[:,:K])\n",
    "    out = np.matmul(Uk,X)\n",
    "    return (out)\n",
    "#I set variable K to 10 for testing:\n",
    "PCA = getKComponents(U,X_scaled,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-5: Compute Reconstruction Error\n",
    "Implement a function to compute the variance ratio (from reconstruction error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00 -9.36176040e-28 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -9.36176040e-28 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -9.36176040e-28 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.05969940e-14 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.05969940e-14 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.74919934e-07 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "5.575252052868255e-22\n",
      "2.229485115372503e-07\n",
      "2.5006904125200855e-15\n"
     ]
    }
   ],
   "source": [
    "def getVarianceRatio(PCA, K, X):\n",
    "    #Implement computation of reconstruction error\n",
    "    # Average of the values in each row of U\n",
    "    mean_rows = np.mean(PCA, axis=0)\n",
    "\n",
    "    # Standard Deviation of the values in each row of U\n",
    "    std_PCA_rows = PCA.std(axis=0)   \n",
    "    \n",
    "    #XApproximated:\n",
    "    Xapprox = (PCA-mean_rows)/std_PCA_rows\n",
    "    \n",
    "    Xpow = X[:K,:]\n",
    "    for i in range(Xpow.shape[1]):\n",
    "        Xpow[:,i] = Xpow[:,i]**i\n",
    "\n",
    "    for i in range(Xapprox.shape[1]):\n",
    "        Xapprox[:,i] = Xpow[:,i]**i\n",
    "    \n",
    "    m=X.shape[0]*X.shape[1]\n",
    "    \n",
    "    sub=Xapprox-Xpow\n",
    "    print(sub)\n",
    "    print(1/m*sum(sum(abs(sub)**2)))\n",
    "    print(1/m*sum(sum(abs(Xpow)**2)))\n",
    "    \n",
    "    #Reconstruction Error:\n",
    "    recErr = (1/m*sum(sum((abs(sub)**2))))/(1/m*sum(sum(abs(Xpow)**2)))\n",
    "    return (recErr)\n",
    "\n",
    "recErr = getVarianceRatio(PCA,10,X_scaled)\n",
    "print(recErr)\n",
    "\n",
    "    #Xapprox = Uk.Z\n",
    "    #ratio = (1/m sgm[i=1,m]||x^i-xapprox^i||^2)/(1/m sgm[i=1,m]||x^i||^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-6: Scatter plot 2-dimensional PCA\n",
    "Using matplotlib plot the 2-dimensional scatter plot of the first 2 compoenents with y (target) as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, ''), Text(0, 0, '5'), Text(0, 0, '0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO Plot the scatter plot \n",
    "#plot PCA[:,:2] using y[0] and y[1] as labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(PCA[:,:2])\n",
    "ax1.set_xticklabels(['',y[0],y[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the minimum value of $K$ with which the ratio between averaged squared projection error with total variation in data is less than 10% in other words we retain 90% of the variance. You can achieve this by repeating getKComponents with $K=1$ until the variance ratio is <= 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-7: TSNE visualization\n",
    "Finally, having found an optimal $K$ use these components as an input data to another dimensionality reduction method called tSNE (https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) and reduce it to 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 50)\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 10000 samples in 0.062s...\n",
      "[t-SNE] Computed neighbors for 10000 samples in 24.497s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 10000\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 10000\n",
      "[t-SNE] Mean sigma: 5.415166\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 81.412766\n",
      "[t-SNE] KL divergence after 300 iterations: 2.731964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "rndperm = np.random.permutation(mnist.data.shape[0])\n",
    "n_sne = 10000 #it is sufficient if done for 10k samples\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "\n",
    "pca_result_50 = np.transpose(getKComponents(U,X_scaled,50))\n",
    "\n",
    "tsne_pca_results = tsne.fit_transform(pca_result_50[rndperm[:n_sne]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, scatter plot the components given by the tSNE using matplotlib compare it to the earlier scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, ''), Text(0, 0, '5'), Text(0, 0, '0')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Scatter plot the 2-dimensional tsne compoents with target as labels\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(tsne_pca_results[:,:2])\n",
    "ax1.set_xticklabels(['',y[0],y[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
