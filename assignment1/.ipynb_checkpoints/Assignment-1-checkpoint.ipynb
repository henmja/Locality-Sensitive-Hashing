{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment the goal is to implement the dimensionality reduction technique *Principal Component Analysis (PCA)* to a very high dimensional data and apply visualization. Note that you are not allowed to use the built-in PCA API provided by the sklearn library. Instead you will be implementing from the scratch.\n",
    "\n",
    "    For this task we use the MNIST dataset. First we download the dataset using openml api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', cache=False)\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1: Preprocessing\n",
    "Before implementing PCA you are required to perform some preprocessing steps:\n",
    "1. Mean normalization: Replace each feature/attribute, $x_{ji}$ with $x_j - \\mu_j$, In other words, determine the mean of each feature set, and then for each feature subtract the mean from the value, so we re-scale the mean to be 0 \n",
    "2. Feature scaling: If features have very different scales then scale make them comparable by altering the scale, so they all have a comparable range of values e.g. $x_{ji}$ is set to $(x_j - \\mu_j) / s_j$  Where $s_j$ is some measure of the range, so could be  $\\max(x_j) - \\min(x_j)$ or Standard deviation $stddev(x_j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n",
      "(70000,)\n",
      "[[-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " ...\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]\n",
      " [-35.10841837 -39.6619898  -24.7997449  ... -37.28443878 -33.87627551\n",
      "  -53.35841837]]\n",
      "[[-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " ...\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]\n",
      " [-0.44079014 -0.47280168 -0.37816163 ... -0.44463709 -0.42776375\n",
      "  -0.5574036 ]]\n"
     ]
    }
   ],
   "source": [
    "#TODO Implement mean normalization and feature scaling\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#transpose X:\n",
    "Xt = np.transpose(X)\n",
    "# Average of the values in each row of X\n",
    "ave_rows = np.mean(Xt, axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each row of X\n",
    "std_rows = Xt.std(axis=0)    \n",
    "\n",
    "#should be same number of rows as in X.shape:\n",
    "# Print the shape of ave_rows\n",
    "print(ave_rows.shape)\n",
    "# Print the shape of std_rows\n",
    "print(std_rows.shape)\n",
    "\n",
    "#Mean normalization of X\n",
    "X_norm = (Xt - ave_cols)\n",
    "\n",
    "#Feature Scaling of X\n",
    "X_scaled = X_norm/std_cols\n",
    "\n",
    "print(X_norm)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2: Covariance matrix\n",
    "Now the preprocessing is finished. Next, as explained in the lecture, you need to compute the covariance matrix https://en.wikipedia.org/wiki/Covariance_matrix. Given $n \\times m$ $n$ rows and $m$ columns matrix, a covariance matrix is an $n \\times n$ matrix given as below (sigma)\n",
    "$\\Sigma = \\frac{1}{m}\\sum{\\left(x^{i}\\right)\\times \\left(x^{i}\\right)^{T}}$\n",
    "You may use the \"numpy.cov\" function in numpy library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " ...\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]\n",
      " [0.00590748 0.00590748 0.00590748 ... 0.00590748 0.00590748 0.00590748]]\n"
     ]
    }
   ],
   "source": [
    "#TODO Compute X to covariance matrix cov_matrix.\n",
    "cov_matrix = np.cov(X_scaled)\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-3: SVD computation\n",
    "Now compute the SVD on the covariance matrix $SVD(\\Sigma)$. You may use the svd implementation in numpy.linalg.svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00574346 -0.00406003 -0.00156353 ...  0.18398401 -0.43351197\n",
      "   0.21373349]\n",
      " [-0.00574346 -0.00406003 -0.00156353 ... -0.15768476  0.01236295\n",
      "   0.15352689]\n",
      " [-0.00574346 -0.00406003 -0.00156353 ...  0.01426123 -0.18272744\n",
      "  -0.27354152]\n",
      " ...\n",
      " [-0.00574346 -0.00406003 -0.00156353 ...  0.00255002 -0.01247046\n",
      "  -0.03903776]\n",
      " [-0.00574346 -0.00406003 -0.00156353 ...  0.00255002 -0.01247046\n",
      "  -0.03903776]\n",
      " [-0.00574346 -0.00406003 -0.00156353 ...  0.00255002 -0.01247046\n",
      "  -0.03903776]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def getSVD(temp):\n",
    "    U, S, V = np.linalg.svd(temp,  full_matrices=False)\n",
    "    return (U,S,V)\n",
    "U,S,V = getSVD(cov_matrix) #SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-4: Compute PCA matrix (K dimensional)\n",
    "Now select the first $k$ columns from the matrix $U$ and multiply with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.59305587  1.00329355  2.25065173 ... -0.44940616 -1.40721551\n",
      "   1.17535297]\n",
      " [ 0.10462511  1.32628427 -0.35456838 ... -2.51856169 -0.71230292\n",
      "   1.10127436]\n",
      " [-0.89183062  1.30367771  0.53647554 ...  0.76123173  1.39925584\n",
      "   1.98449917]\n",
      " ...\n",
      " [-0.66310327 -0.93858969  0.17883476 ... -1.17276335 -0.47698188\n",
      "  -1.57966912]\n",
      " [ 0.45425095  0.73788346  0.012686   ...  0.1178245   1.2265923\n",
      "   0.54927186]\n",
      " [-1.5679233  -1.74273966 -1.49305582 ... -1.32327914 -1.53879954\n",
      "  -0.88370852]]\n",
      "70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henri\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in square\n",
      "C:\\Users\\henri\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in add\n",
      "C:\\Users\\henri\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in power\n"
     ]
    }
   ],
   "source": [
    "def getKComponents(U, X, K):\n",
    "    #TODO implement matrix multiplication of first k columns of U * X\n",
    "    Uk = np.transpose(U[:,:K])\n",
    "    out = np.matmul(Uk,X)\n",
    "    return (out)\n",
    "#I set variable K to 30 for testing:\n",
    "PCA = getKComponents(U,X_scaled,30)\n",
    "\n",
    "#mean_rows = np.mean(PCA, axis=0)\n",
    "\n",
    "    # Standard Deviation of the values in each row of U\n",
    "#std_PCA_rows = PCA.std(axis=0)   \n",
    "#Xapprox = (PCA-mean_rows)/std_PCA_rows\n",
    "#print(Xapprox)\n",
    "#print(X.shape[0])\n",
    "\n",
    "#m = 0\n",
    "#sumCtr = 0\n",
    "#for i in range(X_scaled[:30,:].shape[0]):\n",
    "#    for j in range(X_scaled[:30,:].shape[1]):\n",
    "#        sumCtr = sumCtr + abs(X_scaled[i,j]**j-Xapprox**j)**2\n",
    "#        m = m+1\n",
    "#sumCtr = sumCtr/m\n",
    "\n",
    "#m = 0\n",
    "#sumDen = 0\n",
    "#for i in range(X_scaled[:30,:].shape[0]):\n",
    "#    for j in range(X_scaled[:30,:].shape[1]):\n",
    "#        sumDen = sumDen + abs(X_scaled[i,j]**j)**2\n",
    "#        m = m+1\n",
    "#sumDen = sumDen/m\n",
    "\n",
    "#recErr = sumCtr/sumDen\n",
    " \n",
    "#print(recErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-5: Compute Reconstruction Error\n",
    "Implement a function to compute the variance ratio (from reconstruction error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-93-66e02b13050e>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-93-66e02b13050e>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    recErr = (1/K*abs(X-Xapprox)**2.sum())/((1/K*abs(X)**2).sum())\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def getVarianceRatio(PCA, K, X):\n",
    "    #Implement computation of reconstruction error\n",
    "    # Average of the values in each row of U\n",
    "    mean_rows = np.mean(PCA, axis=0)\n",
    "\n",
    "    # Standard Deviation of the values in each row of U\n",
    "    std_PCA_rows = PCA.std(axis=0)   \n",
    "    Xapprox = (PCA-mean_rows)/std_PCA_rows\n",
    "    print(Xapprox)\n",
    "    #i=\n",
    "    recErr = (1/30*sum(abs(X[:30,:]**i-Xapprox**i)**2))/(1/30*sum(abs(X[:30,:]**i)**2))\n",
    "    return (recErr)\n",
    "\n",
    "getVarianceRatio(PCA,30,X_scaled)\n",
    "print(recErr)\n",
    "\n",
    "    #Xapprox = Uk.Z\n",
    "    #ratio = (1/m sgm[i=1,m]||x^i-xapprox^i||^2)/(1/m sgm[i=1,m]||x^i||^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-6: Scatter plot 2-dimensional PCA\n",
    "Using matplotlib plot the 2-dimensional scatter plot of the first 2 compoenents with y (target) as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Plot the scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the minimum value of $K$ with which the ratio between averaged squared projection error with total variation in data is less than 10% in other words we retain 90% of the variance. You can achieve this by repeating getKComponents with $K=1$ until the variance ratio is <= 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-7: TSNE visualization\n",
    "Finally, having found an optimal $K$ use these components as an input data to another dimensionality reduction method called tSNE (https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) and reduce it to 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "rndperm = np.random.permutation(mnist.data.shape[0])\n",
    "n_sne = 10000 #it is sufficient if done for 10k samples\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_pca_results = tsne.fit_transform(pca_result_50[rndperm[:n_sne]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, scatter plot the components given by the tSNE using matplotlib compare it to the earlier scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Scatter plot the 2-dimensional tsne compoents with target as labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
