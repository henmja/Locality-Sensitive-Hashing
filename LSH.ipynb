{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk import ngrams\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_json(\"data/assignment3_aricles.json\", orient='records', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Title</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A North Carolina woman is trying to warn other...</td>\n",
       "      <td>Facebook Friend Request Nearly Cost One North ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...</td>\n",
       "      <td>Amlin plc UK Regulatory Announcement: Total Vo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...</td>\n",
       "      <td>Khaleda asks for security</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Tikcro enters into research and license agreem...   \n",
       "1  A North Carolina woman is trying to warn other...   \n",
       "2  LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...   \n",
       "3  Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...   \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...   \n",
       "\n",
       "                                               Title  article_id  \n",
       "0  Tikcro enters into research and license agreem...           0  \n",
       "1  Facebook Friend Request Nearly Cost One North ...           1  \n",
       "2  Amlin plc UK Regulatory Announcement: Total Vo...           2  \n",
       "3                          Khaleda asks for security           3  \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Title</th>\n",
       "      <th>article_id</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>0</td>\n",
       "      <td>('Tikcro', 'enters', 'into') ('enters', 'into'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A North Carolina woman is trying to warn other...</td>\n",
       "      <td>Facebook Friend Request Nearly Cost One North ...</td>\n",
       "      <td>1</td>\n",
       "      <td>('A', 'North', 'Carolina') ('North', 'Carolina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...</td>\n",
       "      <td>Amlin plc UK Regulatory Announcement: Total Vo...</td>\n",
       "      <td>2</td>\n",
       "      <td>('LONDONBUSINESS', 'WIRE\\n\\nAMLIN', 'plc\\n\\nTO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...</td>\n",
       "      <td>Khaleda asks for security</td>\n",
       "      <td>3</td>\n",
       "      <td>('Khaleda', 'asks', 'for') ('asks', 'for', 'se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>4</td>\n",
       "      <td>('Liberian', 'Health', 'Clinics') ('Health', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Tikcro enters into research and license agreem...   \n",
       "1  A North Carolina woman is trying to warn other...   \n",
       "2  LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...   \n",
       "3  Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...   \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...   \n",
       "\n",
       "                                               Title  article_id  \\\n",
       "0  Tikcro enters into research and license agreem...           0   \n",
       "1  Facebook Friend Request Nearly Cost One North ...           1   \n",
       "2  Amlin plc UK Regulatory Announcement: Total Vo...           2   \n",
       "3                          Khaleda asks for security           3   \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...           4   \n",
       "\n",
       "                                              ngrams  \n",
       "0  ('Tikcro', 'enters', 'into') ('enters', 'into'...  \n",
       "1  ('A', 'North', 'Carolina') ('North', 'Carolina...  \n",
       "2  ('LONDONBUSINESS', 'WIRE\\n\\nAMLIN', 'plc\\n\\nTO...  \n",
       "3  ('Khaleda', 'asks', 'for') ('asks', 'for', 'se...  \n",
       "4  ('Liberian', 'Health', 'Clinics') ('Health', '...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can use n-gram at word level for this task\n",
    "#try with different n-gram values \n",
    "# You can use ngrams from nltk for this\n",
    "def getNgrams(articles):\n",
    "    n_grams = []\n",
    "    #return articles with a field ngrams\n",
    "    for content in articles['Content']:\n",
    "        n = 3\n",
    "        content = content.split(' ')\n",
    "        content = [x.strip().replace('-', '') for x in content]\n",
    "        content = [x.strip().replace('?', '') for x in content]\n",
    "        content = [x.strip().replace(':', '') for x in content]\n",
    "        content = [x.strip().replace('/', '') for x in content]\n",
    "        content = [x.strip().replace('.', '') for x in content]\n",
    "        content = [x.strip().replace(',', '') for x in content]\n",
    "        content = [x.strip().replace('\\\\', '') for x in content]\n",
    "        content = [x.strip().replace('(', '') for x in content]\n",
    "        content = [x.strip().replace(')', '') for x in content]\n",
    "        content = [x.strip().replace(\"'\", '') for x in content]\n",
    "        content = [x.strip().replace('\"', '') for x in content]\n",
    "        word_grams = []\n",
    "        ngram = ngrams(content,n)\n",
    "        word_grams.append(' '.join(str(i) for i in ngram))\n",
    "        tmp = word_grams[0]\n",
    "        n_grams.append(str(tmp))\n",
    "    articles['ngrams'] = pd.Series(n_grams) #make new field 'ngrams'. Ngrams are the different sequences of length n in articles.\n",
    "getNgrams(articles)\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert n-grams into binary vector representation for each document. You can do some optimzations if the matrix is too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tikcro enters into\n"
     ]
    }
   ],
   "source": [
    "articles['ngrams'] = articles['ngrams'].str.lower()\n",
    "articles['ngrams'] = articles['ngrams'].str.replace(\"', '\",' ').str.split(\"'\\) \\('\")\n",
    "for i,x in enumerate(articles['ngrams']):\n",
    "    articles['ngrams'][i][0] = articles['ngrams'][i][0].replace(\"('\",'')\n",
    "    articles['ngrams'][i][len(articles['ngrams'][i])-1] = articles['ngrams'][i][len(articles['ngrams'][i])-1].replace(\"')\",'')\n",
    "print(articles.ngrams[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48505, 7951814)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "docs = articles.index\n",
    "indptr = [0] \n",
    "indices = [] \n",
    "data = [] \n",
    "vocabulary = {} \n",
    "for d in docs:\n",
    "    unique_ngrams = list(set(articles.ngrams[d]))\n",
    "    for ngram in unique_ngrams:\n",
    "        #if ngram in uniqueShingles\n",
    "        index = vocabulary.setdefault(ngram, len(vocabulary)) \n",
    "        indices.append(index) \n",
    "        data.append(1) \n",
    "    indptr.append(len(indices))\n",
    "binaryMatrix = csr_matrix((data, indices, indptr), dtype=int)\n",
    "print(binaryMatrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need hash function that maps integers 0, 1, . . . , k − 1 to bucket numbers 0 through k − 1. It might be impossible to avoid collisions but as long as the collions are too many it won't matter much.\n",
    "\n",
    "* The simplest would be using the builtin hash() function, it can be for example, hash(rownumber) % Numberofbuckets\n",
    "* You can generate several of these hash functions by xoring a random integer (hash(rownumber)^randint) % Numberofbuckets\n",
    "* It can also be a as simple as (rownumber * randint) % Numberofbuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "hashValMatrix = np.memmap('LSH.hashValMatrix', dtype=np.float64, mode='w+',shape=(binaryMatrix.shape[1],200))\n",
    "def getHashFunctionValues(numrows, numhashfunctions):\n",
    "    #return a matrix with hash values \n",
    "    numBuckets = numrows  \n",
    "    rand_int = [random.randint(1, numrows) for i in range(0,numhashfunctions)]\n",
    "    for i in range(0,numrows):\n",
    "        hashValMatrix[i,:] = [(i^rand_int[j]) % numBuckets for j in range(numhashfunctions)] \n",
    "        #hashValMatrix[i,:] = [(i*rand_int[j]) % numBuckets for j in range(numhashfunctions)] \n",
    "    return hashValMatrix\n",
    "\n",
    "hashValMatrix=getHashFunctionValues(numrows=binaryMatrix.shape[1], numhashfunctions=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute minhash following the faster algorithm from the lecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 48505)\n",
      "(200, 48505)\n"
     ]
    }
   ],
   "source": [
    "sign_matrix = np.memmap('LSH.sign_matrix', dtype=np.float64, mode='w+',shape=(hashValMatrix.shape[1],binaryMatrix.shape[0]))\n",
    "print(sign_matrix.shape)\n",
    "\n",
    "def getMinHashSignatureMatrix(binary_matrix, hash_val_matrix):\n",
    "#return minhash signature matrix \n",
    "    for row in range(binary_matrix.shape[0]):\n",
    "        #Column indices for row:\n",
    "        ind = binary_matrix.indices[binary_matrix.indptr[row]:binary_matrix.indptr[row+1]]\n",
    "        #indices of nonzero elements in row \n",
    "        for hash_col in range(hash_val_matrix.shape[1]): \n",
    "            #add column values for row:\n",
    "            sign_matrix[hash_col,row] = min(hash_val_matrix[:,hash_col][ind]) \n",
    "    return sign_matrix\n",
    "#columns = signatures\n",
    "sign_matrix = getMinHashSignatureMatrix(binaryMatrix, hashValMatrix)\n",
    "print(sign_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash signature bands into buckets. Find a way to combine all the signature values in a band and hash them into a number of buckets ususally very high.\n",
    "* Easiest way is to add all the signature values in the bucket and use a similar hash function like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0, 34401]\n",
      "1\n",
      "[0, 34401, 0]\n",
      "2\n",
      "[0, 34401, 0, 0]\n",
      "3\n",
      "[0, 34401, 0, 0, 0, 6622]\n",
      "4\n",
      "[0, 34401, 0, 0, 0, 6622, 0, 5103]\n",
      "5\n",
      "[0, 34401, 0, 0, 0, 6622, 0, 5103, 0, 19923]\n",
      "6\n",
      "[0, 34401, 0, 0, 0, 6622, 0, 5103, 0, 19923, 0, 6875]\n",
      "7\n",
      "[0, 34401, 0, 0, 0, 6622, 0, 5103, 0, 19923, 0, 6875, 0]\n",
      "8\n",
      "[0, 34401, 0, 0, 0, 6622, 0, 5103, 0, 19923, 0, 6875, 0, 0]\n",
      "9\n",
      "[0, 34401, 0, 0, 0, 6622, 0, 5103, 0, 19923, 0, 6875, 0, 0, 0, 1801]\n",
      "removed duplicates\n",
      "[0, 34401, 1801, 5103, 19923, 6875, 6622]\n",
      "removed articles i from lists of neighbours of i\n",
      "[34401, 1801, 5103, 19923, 6875, 6622]\n"
     ]
    }
   ],
   "source": [
    "#1. divide signature matrix into bands of rows (divide into b parts of r rows).\n",
    "#2. for each band, map each column to a integer/bucket number. can use same hash function for all bands.\n",
    "#3. candidate pair: hashed to same bucket using atleast one band\n",
    "import itertools\n",
    "from itertools import repeat\n",
    "from collections import OrderedDict\n",
    "def getLSH(signature_matrix, num_bands, num_buckets):\n",
    "    signature_matrix_transposed = np.transpose(signature_matrix) #transpose before splitting on columns\n",
    "    bands = np.hsplit(signature_matrix_transposed, num_bands) #b = 20, r = 5\n",
    "    all_buckets = [None]*num_bands\n",
    "    buckets = [[] for i in repeat(None, num_buckets)]\n",
    "    final_buckets = [[] for i in repeat(None, num_buckets)]\n",
    "    tempSum = np.empty((signature_matrix.shape[1]))\n",
    "    \n",
    "    for i,band in enumerate(bands):\n",
    "        print(i)\n",
    "        band = np.transpose(band)\n",
    "        for article in range(band.shape[1]):\n",
    "            tempSum[article] = np.sum(band[:,article]) % num_buckets #can use same hash function for all bands -> no need for randint\n",
    "        for article in range(band.shape[1]):\n",
    "            buckets[article] = list(buckets[article])+list(np.where(tempSum==tempSum[article])[0])#+1)\n",
    "        print(buckets[0])\n",
    "    \n",
    "    #LIST SET ALL ELEMENTS IN FINAL_BUCKETS\n",
    "    for i,bucket in enumerate(buckets):\n",
    "        buckets[i] = list(set(bucket))\n",
    "    print('removed duplicates')\n",
    "    print(buckets[0])\n",
    "    for i, bucket in enumerate(buckets):\n",
    "        buckets[i].remove(i)#+1)\n",
    "    print('removed articles i from lists of neighbours of i')\n",
    "    print(buckets[0])\n",
    "    return buckets\n",
    "nearest_neighbours = getLSH(sign_matrix,10,48505)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune parameters to make sure the threshold is appropriate.\n",
    "## plot the probability of two similar items falling in same bucked for different threshold values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "[0.0, 0.00019998100113904904, 0.0063805813047682625, 0.04749425912497118, 0.1860495521491441, 0.4700507153168765, 0.8019024538382217, 0.9747805441880405, 0.9996439421094793, 0.9999999824090121, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "num_bands = 20\n",
    "r = 5\n",
    "x_axis = [float(x/10) for x in range(0,11)]\n",
    "print(x_axis)\n",
    "y_axis = [1-(1-t**r)**num_bands for t in x_axis]\n",
    "print(y_axis)\n",
    "plt.scatter(x_axis,y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best parameters and get nearest neighbors of each articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results to submissions.csv file and get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write article ids, nearest neighbours (documents in same buckets)\n",
    "import csv\n",
    "index = 0\n",
    "article_ids=[]\n",
    "for nearestNeighbours in nearest_neighbours:\n",
    "    for neighbour in nearestNeighbours:\n",
    "        article_ids.append(index)\n",
    "    index = index+1\n",
    "nearest_neighbours_single_list = [item for sublist in nearest_neighbours for item in sublist]\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = article_ids #article IDs\n",
    "sub['NearestNeighbours'] = nearest_neighbours_single_list\n",
    "sub.to_csv('submissions.csv', index=False, escapechar=' ', quoting=csv.QUOTE_NONE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
