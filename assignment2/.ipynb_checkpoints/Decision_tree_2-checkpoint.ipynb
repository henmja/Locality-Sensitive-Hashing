{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "#import time\n",
    "alldata = np.loadtxt('data/housing_price_train.csv',dtype='<U20',delimiter=',')\n",
    "testdata = np.loadtxt('data/housing_price_test.csv',dtype='<U20',delimiter=',')\n",
    "def hist(vals,n_block,attr_name,bins=None):\n",
    "    if not bins:\n",
    "        n,bins,patches=plt.hist(vals, bins=n_block,alpha =0.5 )\n",
    "    else:\n",
    "        n,bins,patches =plt.hist(vals, bins=bins,alpha=0.5)\n",
    "    plt.title('Histogram of ' + attr_name)\n",
    "    plt.xlabel(attr_name)\n",
    "    plt.ylabel('Counts')\n",
    "    plt.savefig('hists/'+attr_name+'_hist.png')\n",
    "    plt.close()\n",
    "    return n,bins,patches\n",
    "test_pre_attr_names = testdata[0]\n",
    "test_attr_names = test_pre_attr_names[1:]\n",
    "pre_attr_names = alldata[0]\n",
    "pre_data= np.transpose(np.copy(alldata[1:]))\n",
    "test_data = np.transpose(np.copy(testdata[1:]))\n",
    "test_data = np.copy(test_data)\n",
    "test_attr_names =np.copy(test_pre_attr_names)\n",
    "prices = np.log10(np.float64(pre_data[-1]))\n",
    "pre_data= np.copy(pre_data[1:-1])\n",
    "pre_attr_names = np.copy(pre_attr_names[1:-1])\n",
    "neigh_ind = np.where(pre_attr_names=='Neighborhood')[0][0]\n",
    "neighborhoods = np.unique(pre_data[neigh_ind])\n",
    "bad_attrs= np.array(['3SsnPorch','Alley','MoSold','PoolQC',\n",
    "                     'Utilities','YrSold','LandSlope',\n",
    "                     'LotFrontage','MasVnrType','MasVnrArea','BsmtQual',\n",
    "                     'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "                     'Electrical','FireplaceQu','GarageType','GarageYrBlt',\n",
    "                     'GarageFinish','GarageQual','GarageCond','Fence','MiscFeature',\n",
    "                     'PoolArea','Street',])\n",
    "                     #'1stFlrSF','2ndFlrSF','BsmtFinSF1','BsmtFinSF2','Neighborhood'])\n",
    "#last row of things is getting rid of redundancies\n",
    "good_attrs = np.array([[pre_attr_names[i],i]  for i in range(len(pre_attr_names)) if (pre_attr_names[i] not in bad_attrs)])\n",
    "attr_names = good_attrs[:,0]\n",
    "data = pre_data[np.int64(good_attrs[:,1])]\n",
    "data_by_neighborhood ={} \n",
    "price_by_neighborhood = {}\n",
    "for neighborhood in neighborhoods:\n",
    "    neighbors_inds = np.where(data[neigh_ind,:] ==neighborhood)[0]\n",
    "    neighbors_data = data[:,neighbors_inds]\n",
    "    neighbors_prices = prices[neighbors_inds]\n",
    "    data_by_neighborhood[neighborhood] =[neighbors_data,neighbors_data,neighbors_prices]\n",
    "def fixna(attr):\n",
    "    return\n",
    "def plotcor(vals,prices,name):\n",
    "    try:\n",
    "        uvals = np.copy(np.float64(vals))\n",
    "        plt.plot(uvals,prices,'o')\n",
    "        plt.xlabel(name)\n",
    "        plt.ylabel('log(Price)')\n",
    "        plt.savefig('cor/'+name+'_cor.png') \n",
    "        plt.close()\n",
    "    except:\n",
    "        uniq_vals,map_ints,val_counts,map_attr = name_to_number(vals)\n",
    "        plt.plot(map_attr, prices,'o')\n",
    "        print(name)\n",
    "        plt.xlabel(name)\n",
    "        plt.ylabel('log(Price)')\n",
    "        plt.savefig('cor/'+name+'_cor.png') \n",
    "        plt.close()\n",
    "def loopcor():\n",
    "    for i in range(len(attr_names)):\n",
    "        plotcor(data[i],prices,attr_names[i])\n",
    "def loophists():\n",
    "    for i  in range(len(attr_names)):#len(attr_names)):\n",
    "        try:\n",
    "            dat= np.copy(np.float64(data[i]))\n",
    "            hist(dat, 20,attr_names[i])\n",
    "        except:\n",
    "            dat = np.copy(data[i])\n",
    "            uniq_vals,map_ints, val_counts=name_to_number(dat)\n",
    "            hist(val_counts, 0, attr_names[i], bins=map_ints)\n",
    "def name_to_number(attribute):\n",
    "    uniq_vals, val_counts = np.unique(attribute,return_counts=True)\n",
    "    map_ints = range(len(uniq_vals))\n",
    "    map_attr = np.copy(attribute)\n",
    "    for i in range(len(uniq_vals)):\n",
    "        all_val = np.where(attribute == uniq_vals[i])[0]\n",
    "        map_attr[all_val] = map_ints[i]\n",
    "        intvals = map_ints[i]\n",
    "        allints = np.ones_like(all_val)*intvals\n",
    "    return [uniq_vals, map_ints, val_counts,map_attr]\n",
    "def counts_arr(attribute):\n",
    "    ''' \n",
    "    Return the unique values and their probabilities\n",
    "    '''\n",
    "    uniq_vals, val_counts=np.unique(attribute,return_counts=True)\n",
    "    val_counts = np.float64(val_counts)\n",
    "    val_probs = val_counts/np.float64(attribute.size)\n",
    "    return uniq_vals, val_probs\n",
    "def get_max_prob(probs):\n",
    "    mxprob= np.where(probs==np.max(probs))[0][0]\n",
    "    return probs[mxprob]\n",
    "def entropy(attribute):\n",
    "    uniq_vals , val_probs =counts_arr(attribute)\n",
    "    return np.sum(val_probs *np.log2(1./val_probs))\n",
    "def info_gain(attribute,labels):\n",
    "    cts_arr =counts_arr(attribute)\n",
    "    label_entropy = entropy(labels)\n",
    "    label_given_attr = []\n",
    "    if type(cts_arr[1]) != np.ndarray:\n",
    "        return label_entropy\n",
    "    cts_dict = dict(zip(cts_arr[0],cts_arr[1]))\n",
    "    for uniq_attr_val,uniq_val_prob in cts_dict.items():\n",
    "        label_given_attr.append( uniq_val_prob *entropy(labels[attribute==uniq_attr_val]))\n",
    "    return label_entropy- np.sum(label_given_attr)\n",
    "def best_attr(data, attribute_names,labels):\n",
    "    gains=np.array([])\n",
    "    for i in data:\n",
    "        gains=np.append( gains, info_gain(i, labels))\n",
    "    maxind = np.where(gains == np.max(gains))[0][0]\n",
    "    maxgn = gains[maxind]\n",
    "    att_name= attribute_names[maxind]\n",
    "    print('Max Gain', maxgn)\n",
    "    return att_name,maxind\n",
    "class Tree:\n",
    "    def __init__(self, attr_split=None,parent=None):\n",
    "        self.parent=parent\n",
    "        self.child=[]\n",
    "        self.attr_split= attr_split\n",
    "    def add_child(self,child):\n",
    "        self.child.append(child)\n",
    "        child.parent= self\n",
    "def finite_combo(arr1,arr2):\n",
    "    finds = np.where( (~np.isnan(arr1)) &(~np.isnan(arr2)))[0]\n",
    "    fin_arr1 = arr1[finds]\n",
    "    fin_arr2 = arr2[finds]\n",
    "    return fin_arr1,fin_arr2,finds\n",
    "def splitdata(attr,labels,attr_name,showplot=False,depth=0):\n",
    "    ''' \n",
    "    Trying to find best spot to split at\n",
    "    '''\n",
    "    try:\n",
    "        attr_dat =np.float64(attr)\n",
    "        uniq_vals,probs = counts_arr(attr)\n",
    "        typ='num'    \n",
    "    except:\n",
    "        uniq_vals,map_ints, val_counts, map_attr = name_to_number(attr)\n",
    "        attr_dat = np.copy(np.float64(map_attr))\n",
    "        typ='nom'\n",
    "        print('Map Attr',map_attr)\n",
    "    if typ =='nom' or len(uniq_vals) <=10:\n",
    "        n_splits = len(uniq_vals)\n",
    "        splits =[]\n",
    "        split_ints = []\n",
    "        for i in range(n_splits):\n",
    "            splits.append([attr==uniq_vals[i] ])\n",
    "            split_ints.append(uniq_vals[i])\n",
    "        threshold_val = np.array([-99])\n",
    "        threshold_type ='NA'\n",
    "    elif len(uniq_vals) >2:\n",
    "        try:\n",
    "            labels = np.float64(labels)\n",
    "            sort_by_attr = np.argsort(attr_dat)\n",
    "            attr_sort = np.copy(attr_dat[sort_by_attr])\n",
    "            label_sort =np.copy(labels[sort_by_attr])\n",
    "            linregslopes_left = []\n",
    "            linregslopes_right = []\n",
    "            for i in range(len(attr_sort)//10,len(attr_sort) -len(attr_sort)//10  ):\n",
    "                attr_l = attr_sort[0:i]\n",
    "                attr_r = attr_sort[i:]\n",
    "                lab_l = label_sort[0:i]\n",
    "                lab_r = label_sort[i:]\n",
    "                m_l,b_l = np.polyfit(attr_l,lab_l,1)\n",
    "                m_r,b_r = np.polyfit(attr_r,lab_r,1)\n",
    "                linregslopes_left.append(abs(m_l))\n",
    "                #ind_left.append(i)\n",
    "                linregslopes_right.append(abs(m_r))\n",
    "                #ind_right.append(i)\n",
    "            linregslopes_left =np.array(linregslopes_left)\n",
    "            linregslopes_right =np.array(linregslopes_right)\n",
    "            finite_left,finite_right,finite_inds = finite_combo(linregslopes_left,linregslopes_right)\n",
    "            inv_left = 1./finite_left\n",
    "            inv_right = 1./finite_right\n",
    "            #lin left = where left side is linear and right is not\n",
    "            linleft=finite_left*inv_right\n",
    "            #linright = where right side is linear and left is not\n",
    "            linright = inv_left*finite_right\n",
    "            finmxleft = np.where(linleft == np.max(linleft))[0][0]\n",
    "            mxleft = np.where(linregslopes_left == finite_left[finmxleft])[0]\n",
    "            #transforming back to the array with infinite (if necessary)\n",
    "            finmxright = np.where(linright == np.max(linright))[0][0]\n",
    "            mxright = np.where(linregslopes_right == finite_right[finmxright])[0]\n",
    "            #if mxleft >mxright:\n",
    "            threshold_val = attr_sort[mxleft+len(attr_sort)//10]\n",
    "            #else:\n",
    "            #    threshold_val = attr_sort[mxright+len(attr_sort)//10]        \n",
    "            if typ=='nom':\n",
    "                split_l = [attr_dat <threshold_val]\n",
    "                split_r = [attr_dat >=threshold_val]\n",
    "                splits=[split_l,split_r]\n",
    "            else:\n",
    "                split_l = [attr_dat<=threshold_val]\n",
    "                split_r= [attr_dat >threshold_val]\n",
    "                splits=[split_l,split_r]\n",
    "            threshold_type='linsplit'\n",
    "            split_ints =[]\n",
    "        except:\n",
    "            threshold_val = np.array([np.mean(attr_dat)])\n",
    "            split_l =[attr_dat < threshold_val]\n",
    "            split_r = [attr_dat >= threshold_val]\n",
    "            splits = [split_l,split_r]\n",
    "            threshold_type = 'linsplit'\n",
    "            split_ints = []\n",
    "    if showplot: \n",
    "        plt.plot(attr_dat, labels,'o')\n",
    "        plt.axvline(x=threshold_val,label='Threshold = '+str(threshold_val))\n",
    "        plt.ylabel('log(Price))')\n",
    "        plt.xlabel(attr_name)\n",
    "        plt.legend()\n",
    "        plt.savefig('thresholds/'+attr_name +'_threshold_depth'+str(depth)+'png')\n",
    "        plt.close()\n",
    "    return splits,threshold_val,threshold_type,split_ints,typ #threshold_val, mxleft, mxright\n",
    "def pure(vals):\n",
    "    return len(np.unique(vals))==1\n",
    "def decisionTree(dat,attribute_names,labels,root=None,depth=0):\n",
    "    '''\n",
    "    get bestattr, threshold for split, and then values\n",
    "    which align along the splits and repeat\n",
    "    '''\n",
    "    if dat[0] ==[]:\n",
    "        root.avg_label = root.parent.avg_label\n",
    "        return #root#root.parent.avg_label\n",
    "    if len(dat[0]) <5:\n",
    "        root.avg_label= np.mean(labels)#root#return root.parent.avg_label\n",
    "        return\n",
    "    bestattr,maxind= best_attr(dat,attribute_names,labels)\n",
    "    if not root:\n",
    "        root = Tree()\n",
    "    root.split_attr =bestattr\n",
    "    root.split_attr_ind=maxind\n",
    "    attr_data = np.copy(dat[maxind])\n",
    "    if pure(attr_data):\n",
    "        root.avg_label= np.mean(labels)\n",
    "        return \n",
    "    splits,threshold_val, threshold_type,split_ints,typ=splitdata(attr_data,labels,bestattr,showplot=False,depth=depth)\n",
    "    trees = []\n",
    "    for i in range(len(splits)):\n",
    "        trees.append(Tree(parent=root))\n",
    "        root.add_child(trees[i])\n",
    "        root.split_ints = split_ints\n",
    "        trees[i].inds_filt = splits[i][0]\n",
    "        \n",
    "    root.threshold_val =threshold_val\n",
    "    root.threshold_type = threshold_type\n",
    "    root.typ = typ\n",
    "    root.avg_label= np.mean(labels)\n",
    "    depth+=1\n",
    "    red= [attribute_names!=bestattr]\n",
    "\n",
    "    red_attr_names = attribute_names[red]\n",
    "    red_data = dat[red]\n",
    "    for tree in trees:\n",
    "        decisionTree(red_data[:,tree.inds_filt],red_attr_names,labels[tree.inds_filt],root=tree,depth=depth)\n",
    "    return root \n",
    "price_by_id = {}\n",
    "dT = decisionTree(data,attr_names, prices)\n",
    "def predictlabels(dat,attr_names,dTree,predTree = None,labels=[]):\n",
    "    if len(dat[0]) == 0:\n",
    "        return\n",
    "    if len(labels) == 0:\n",
    "        labels = np.ones_like(dat[0])\n",
    "    if len(dTree.child) ==0:\n",
    "        for tid in dat[0]:\n",
    "            price_by_id[tid] = dTree.avg_label \n",
    "        return\n",
    "    if not predTree:\n",
    "        predTree = Tree()\n",
    "    attr_split = dTree.split_attr \n",
    "    attr_split_ind =np.where(attr_names == attr_split)[0]\n",
    "    attr_split_ints = dTree.split_ints\n",
    "    attr_dat = dat[attr_split_ind][0] #these are still stored as strings\n",
    "    thresh_type = dTree.threshold_type\n",
    "    thresh_val = np.float64(dTree.threshold_val[0])\n",
    "    try:\n",
    "        attr_data =np.float64(attr_dat)\n",
    "        uniq_vals,probs = counts_arr(attr_dat)\n",
    "    except:\n",
    "        uniq_vals,map_ints, val_counts, map_attr = name_to_number(attr_dat)\n",
    "        attr_data = np.copy(np.float64(map_attr))\n",
    "    typ = dTree.typ\n",
    "    predTree.attr_split = attr_split\n",
    "    if thresh_type=='0':\n",
    "        split_l = np.where(attr_data == 0)[0]\n",
    "        split_r = np.where(attr_data > 0)[0]\n",
    "        splits = [split_l,split_r]\n",
    "    elif thresh_type=='linsplit':\n",
    "        if typ=='nom':\n",
    "            split_l = np.where(attr_data <thresh_val)[0]\n",
    "            split_r = np.where(attr_data >=thresh_val)[0]\n",
    "            splits=[split_l,split_r]\n",
    "        else:\n",
    "            split_l = np.where(attr_data<=thresh_val)[0]\n",
    "            split_r= np.where(attr_data >thresh_val)[0]       \n",
    "            splits=[split_l,split_r]   \n",
    "    elif thresh_type == 'NA':\n",
    "        splits =[]\n",
    "        for val in attr_split_ints:\n",
    "            splits.append(np.where(attr_data==val)[0])    \n",
    "    trees = []\n",
    "    for i in range(len(splits)):\n",
    "        trees.append(Tree(parent=predTree))\n",
    "        predTree.add_child(trees[i])\n",
    "        trees[i].label_inds = splits[i]\n",
    "        trees[i].dtree = dTree.child[i]\n",
    "        trees[i].avg_label =dTree.avg_label\n",
    "        predictlabels(dat[:,trees[i].label_inds],attr_names,trees[i].dtree, predTree= trees[i],labels=labels)\n",
    "    tids = dat[0]\n",
    "    labs =[]\n",
    "    for tid in tids:\n",
    "        try:\n",
    "            labs.append(price_by_id[tid])\n",
    "        except:\n",
    "            labs.append(np.median(list(price_by_id.values() )))\n",
    "    return labs\n",
    "p = predictlabels(test_data, test_attr_names,dT)\n",
    "def histprices():\n",
    "    plt.hist(prices, bins=10,alpha=0.75,color='g',label='Sale Prices, Train Data')\n",
    "    plt.hist(p, bins=10, alpha = 0.5,color='r',label='Predicted Prices, Test Data')\n",
    "    plt.legend()\n",
    "    plt.xlabel('log(Price)')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.savefig('id3_prices_hist.png')\n",
    "histprices()\n",
    "def writepricebyid():\n",
    "    f = open('data/submission.csv','w+')\n",
    "    f.write('Id,SalePrice\\n')\n",
    "    for i in range(len(test_data[0])):\n",
    "        f.write(str(test_data[0][i])+','+str(10**p[i]) +'\\n')\n",
    "    f.close()\n",
    "writepricebyid()\n",
    "def tree_info(tree):\n",
    "    print(tree.split_attr)\n",
    "    print(tree.threshold_val)\n",
    "    print(tree.avg_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
