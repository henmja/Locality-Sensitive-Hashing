{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Building a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a skeleton of a decision tree classifier for the example data set in `data/example.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 6}\n",
      "[1 4 1]\n",
      "[0 2]\n",
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "from statistics import median, mode, mean\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,2,3,4],[4,6,7,8],[1,2,3,4]])\n",
    "test = set([A[idx][1] for idx in range(len(A))])\n",
    "print(test)\n",
    "print(A[:,0])\n",
    "test2 = {}\n",
    "test2[1] = []\n",
    "temp = np.where( A[:,0] <= 3 )\n",
    "print(temp[0])\n",
    "\n",
    "test2[1].append(temp[0])\n",
    "print(test2[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some simple type definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrType(Enum):\n",
    "    cat = 0  # categorical (qualitative) attribute\n",
    "    num = 1  # numerical (quantitative) attribute\n",
    "    target = 2  # target label\n",
    "\n",
    "\n",
    "class NodeType(Enum):\n",
    "    root = 0\n",
    "    internal = 1\n",
    "    leaf = 2\n",
    "\n",
    "\n",
    "class SplitType(Enum):\n",
    "    bin = 0  # binary split\n",
    "    multi = 1  # multi-way split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, some basic classes to represent an attribute, a spltting procedure, and a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute(object):\n",
    "    def __init__(self, label, type):\n",
    "        assert type in AttrType\n",
    "        self.label = label\n",
    "        self.type = type\n",
    "        self.stat = None  # holds mean for numerical and mode for categorical attributes\n",
    "\n",
    "\n",
    "class Splitting(object):\n",
    "    def __init__(self, attr, infogain, split_type, cond, splits):\n",
    "        self.attr = attr  # attribute ID (index in ATTR)\n",
    "        self.infogain = infogain  # information gain if splitting is done on this attribute\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.cond = cond  # splitting condition, i.e., values on outgoing edges\n",
    "        self.splits = splits  # list of training records (IDs) for each slitting condition\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, id, type, parent_id, children=None, edge_value=None, val=None, split_type=None, split_cond=None,\n",
    "                 infogain=None):\n",
    "        self.id = id  # ID (same as the index in DT.model list)\n",
    "        self.type = type  # one of NodeType\n",
    "        self.parent_id = parent_id  # ID of parent node (None if root)\n",
    "        self.children = children  # list of IDs of child nodes\n",
    "        self.edge_value = edge_value  # the value of the incoming edge (only if not root node)\n",
    "        self.val = val  # if root or internal node: the attribute that is compared at that node; if leaf node: the target value\n",
    "        self.split_type = split_type  # one of SplitType\n",
    "        self.split_cond = split_cond  # splitting condition (median value for binary splits on numerical values; otherwise a list of categorical values (corresponding to child nodes))\n",
    "        self.infogain = infogain\n",
    "\n",
    "    def append_child(self, node_id):\n",
    "        self.children.append(node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input filename is hard-coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILE = \"data/housing_price_train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute labels types are hard-coded too (the same order as in the file!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "#Read from training data:\n",
    "with open(INFILE) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    row1 = next(csv_reader)\n",
    "    labels = []\n",
    "    types = []\n",
    "    ATTR = []\n",
    "    \n",
    "    for x in row1:\n",
    "        labels.append(x)\n",
    "    row2 = next(csv_reader)\n",
    "    \n",
    "    types = [AttrType.num, AttrType.num, AttrType.cat, AttrType.num, AttrType.num, AttrType.cat, AttrType.cat, AttrType.cat,\n",
    "            AttrType.cat, AttrType.cat, AttrType.cat, AttrType.cat, AttrType.cat, AttrType.cat, AttrType.cat, AttrType.cat,\n",
    "            AttrType.cat, AttrType.num, AttrType.num, AttrType.num, AttrType.num, AttrType.cat, AttrType.cat, AttrType.cat,\n",
    "            AttrType.cat, AttrType.cat, AttrType.num, AttrType.cat, AttrType.cat, AttrType.cat, AttrType.cat, AttrType.cat,\n",
    "            AttrType.cat, AttrType.cat, AttrType.num, AttrType.cat, AttrType.num, AttrType.num, AttrType.num, AttrType.cat,\n",
    "            AttrType.cat, AttrType.cat, AttrType.cat, AttrType.num, AttrType.num, AttrType.num, AttrType.num, AttrType.num,\n",
    "            AttrType.num, AttrType.num, AttrType.num, AttrType.num, AttrType.num, AttrType.cat, AttrType.num, AttrType.cat,\n",
    "            AttrType.num, AttrType.cat, AttrType.cat, AttrType.num, AttrType.cat, AttrType.num, AttrType.num, AttrType.cat,\n",
    "            AttrType.cat, AttrType.cat, AttrType.num, AttrType.num, AttrType.num, AttrType.num, AttrType.num, AttrType.num,\n",
    "            AttrType.cat, AttrType.cat, AttrType.cat, AttrType.num, AttrType.num, AttrType.num, AttrType.cat, AttrType.cat,\n",
    "            AttrType.target]\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        ATTR.append(Attribute(labels[i],types[i]))\n",
    "        \n",
    "    print(len(labels))\n",
    "    print(len(ATTR))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the target attribute (assuming it's the last)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_TARGET = len(ATTR) - 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main class DT representing the decision tree classifier. It could represent with methods:\n",
    "\n",
    "  - a given impurity measure;\n",
    "  - the search for the best attribute to split with;\n",
    "  - the addition of a node to the tree;\n",
    "  - a convenient model printer;\n",
    "  - the recursive call for obtaining a tree;\n",
    "  - a builder and an applier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT(object):\n",
    "    def __init__(self):\n",
    "        self.data = None  # training data set (loaded into memory)\n",
    "        self.model = None  # decision tree model\n",
    "        self.default_target = 0.0  # default target class\n",
    "\n",
    "    def __load_data(self):\n",
    "        with open(INFILE) as csvfile:\n",
    "            self.data = []\n",
    "            csvreader = csv.reader(csvfile, delimiter=',')\n",
    "            for row in csvreader:\n",
    "                rec = []\n",
    "                for i in range(len(ATTR)):\n",
    "                    val = row[i].strip()\n",
    "                    # convert numerical attributes\n",
    "                    if ATTR[i].type == AttrType.num:  # Note that this will break for \"?\" (missing attribute)\n",
    "                        val = float(val)\n",
    "                    rec.append(val)\n",
    "                self.data.append(rec)\n",
    "                # self.data.append([element.strip() for element in row])  # strip spaces\n",
    "\n",
    "\n",
    "    \n",
    "    def __mean_squared_error(self, records):\n",
    "        \"\"\"\n",
    "        Calculates mean squared error for a selection of records.\n",
    "\n",
    "        :param records: Data records (given by indices)\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        predictions = self.predict(records)\n",
    "        sqe = np.zeros(len(records)) #square error\n",
    "        i = 0\n",
    "        for rec in records:\n",
    "            sqe[i] = (self.data[records,IDX_TARGET]-predictions[records, IDX_TARGET])**2 \n",
    "            i = i+1\n",
    "        MSE = mean(sqe) #mean square error\n",
    "        return MSE\n",
    "\n",
    "    def __find_best_attr(self, attrs, records):\n",
    "        \"\"\"\n",
    "        Finds the attribute with the largest gain.\n",
    "\n",
    "        :param attrs: Set of attributes\n",
    "        :param records: Training set (list of record ids)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        mse_p = self.__mean_squared_error(records)  # parent's MSE\n",
    "        splittings = []  # holds the splitting information for each attribute\n",
    "        numKey = 0\n",
    "        for a in attrs:\n",
    "            assert ATTR[a].type in AttrType\n",
    "            splits = {}  # record IDs corresponding to each split\n",
    "            # splitting condition depends on the attribute type\n",
    "            if ATTR[a].type == AttrType.target:  # skip target attribute\n",
    "                continue\n",
    "            elif ATTR[a].type == AttrType.cat:  # categorical attribute\n",
    "                # multi-way split on each possible value\n",
    "                split_mode = SplitType.multi\n",
    "                # each possible attr value corresponds to a split (indexed with categorical labels)\n",
    "                # Note: it's important to consider attr values from the entire training set\n",
    "                split_cond = set([self.data[idx][a] for idx in range(len(self.data))])\n",
    "                \n",
    "                # TODO collect training records for each split \n",
    "                # `splits[val]` holds a list of records for a given split,\n",
    "                # where `val` is an element of `split_cond`\n",
    "                for val in split_cond: #CATEGORICAL SPLIT\n",
    "                    splits[val] = []\n",
    "                    #index 0 for np.where gir value og datatype:\n",
    "                    splits[val].append(np.where(self.data[:,a]<=val)[0]) # index 0: <= split_cond\n",
    "                    splits[val].append(np.where(self.data[:,a]>val)[0]) # index 1: > split_cond\n",
    "                    \n",
    "            elif ATTR[a].type == AttrType.num:  # numerical attribute => binary split on median value\n",
    "                split_mode = SplitType.bin\n",
    "                split_cond = self.__median(a)  # (i.e., if less or equal than this value)\n",
    "                # TODO collect training records for each split (in `splits`)\n",
    "                splits[split_cond] = [] #NUMERICAL SPLIT\n",
    "                #index 0 for np.where gir value og datatype:\n",
    "                splits[split_cond].append(np.where(self.data[:,a]<=split_cond)[0]) # index 0: <= median\n",
    "                splits[split_cond].append(np.where(self.data[:,a]>split_cond)[0]) # index 1: > \n",
    "                numKey = split_cond\n",
    "            # TODO compute gain for attribute a\n",
    "            infogain = 0\n",
    "            if len(splits)==1: #NUMERIC INFOGAIN\n",
    "                p1 = len(splits[numKey][0])/len(self.data[:,a])\n",
    "                p2 = len(splits[numKey][1])/len(self.data[:,a])\n",
    "                mse_c1 = self.__mean_squared_error(splits[numKey][0])\n",
    "                mse_c2 = self.__mean_squared_error(splits[numkey][1])\n",
    "                infogain = mse_p - (p1*mse_c1+p2*mse_c2)\n",
    "            else if len(splits)>1 #CATEGORICAL INFOGAIN\n",
    "                for x in splits:\n",
    "                    p1 = len(x[0])/len(self.data[:,a])\n",
    "                    p2 = len(x[1])/len(self.data[:,a])\n",
    "                    mse_c1 = self.__mean_squared_error(x[0])\n",
    "                    mse_c2 = self.__mean_squared_error(x[1])\n",
    "                    temp = mse_p - (p1*mse_c1+p2*mse_c2)\n",
    "                    if temp > infogain:\n",
    "                        infogain = temp\n",
    "            \n",
    "            \n",
    "            splitting = Splitting(a, infogain, split_mode, split_cond, splits)\n",
    "            splittings.append(splitting)\n",
    "\n",
    "        # find best splitting (lowest infogain is first element in reversed list)\n",
    "        best_splitting = sorted(splittings, key=lambda x: x.infogain, reverse=True)[0]\n",
    "        return best_splitting\n",
    "\n",
    "    def __add_node(self, parent_id, node_type=NodeType.internal, edge_value=None, val=None, split_type=None,\n",
    "                   split_cond=None):\n",
    "        \"\"\"\n",
    "        Adds a node to the decision tree.\n",
    "\n",
    "        :param parent_id:\n",
    "        :param node_type:\n",
    "        :param edge_value:\n",
    "        :param val:\n",
    "        :param split_type:\n",
    "        :param split_cond:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        node_id = len(self.model)  # id of the newly assigned node\n",
    "        if not self.model:  # the tree is empty\n",
    "            node_type = NodeType.root\n",
    "\n",
    "        node = Node(node_id, node_type, parent_id, children=[], edge_value=edge_value, val=val, split_type=split_type,\n",
    "                    split_cond=split_cond)\n",
    "        self.model.append(node)\n",
    "\n",
    "        # also add it as a child of the parent node\n",
    "        if parent_id is not None:\n",
    "            self.model[parent_id].append_child(node_id)\n",
    "\n",
    "        return node_id\n",
    "\n",
    "    def __id3(self, attrs, records, parent_id=None, value=None):\n",
    "        \"\"\"\n",
    "        Function ID3 that returns a decision tree.\n",
    "\n",
    "        :param attrs: Set of attributes\n",
    "        :param records: Training set (list of record ids)\n",
    "        :param parent_id: ID of parent node\n",
    "        :param value: Value corresponding to the parent attribute, i.e., label of the edge on which we arrived to this node\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # empty training set or empty set of attributes => create leaf node with default class\n",
    "        if not records or not attrs:\n",
    "            self.__add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=self.default_class)\n",
    "            return\n",
    "\n",
    "        # if all records have the same target value => create leaf node with that target value\n",
    "        same = all(self.data[idx][IDX_TARGET] == self.data[records[0]][IDX_TARGET] for idx in records)\n",
    "        if same:\n",
    "            target = self.data[records[0]][IDX_TARGET]\n",
    "            self.__add_node(parent_id, node_type=NodeType.leaf, edge_value=value, val=target)\n",
    "            return\n",
    "\n",
    "        # find the attribute with the largest gain\n",
    "        splitting = self.__find_best_attr(attrs, records)\n",
    "        # add node\n",
    "        node_id = self.__add_node(parent_id, edge_value=value, val=splitting.attr, split_type=splitting.split_type,\n",
    "                                  split_cond=splitting.cond)\n",
    "        # TODO call tree construction recursively for each split\n",
    "\n",
    "    def print_model(self, node_id=0, level=0):\n",
    "        node = self.model[node_id]\n",
    "        indent = \"  \" * level\n",
    "        if node.type == NodeType.leaf:\n",
    "            print(indent + str(node.edge_value) + \" [Leaf node] class=\" + node.val)\n",
    "        else:\n",
    "            cond = \" <= \" + str(node.split_cond) if ATTR[node.val].type == AttrType.num else \" == ? \"\n",
    "            if node.type == NodeType.root:\n",
    "                print(\"[Root node] '\" + ATTR[node.val].label + \"'\" + cond)\n",
    "            else:\n",
    "                print(indent + str(node.edge_value) + \" [Internal node] '\" + ATTR[node.val].label + \"'\" + cond)\n",
    "            # print tree for child notes recursively\n",
    "            for n_id in node.children:\n",
    "                self.print_model(n_id, level + 1)\n",
    "\n",
    "    def build_model(self):\n",
    "        self.__load_data()\n",
    "        self.model = []  # holds the decision tree model, represented as a list of nodes\n",
    "        # Get majority class\n",
    "        #   Note: Counter returns a dictionary, most_common(x) returns a list with the x most common elements as\n",
    "        #         (key, count) tuples; we need to take the first element of the list and the first element of the tuple\n",
    "        self.default_target = mean([x[IDX_TARGET] for x in self.data])\n",
    "        self.__id3(set(range(len(ATTR) - 1)), list(range(len(self.data))))\n",
    "\n",
    "    def apply_model(self, record):\n",
    "        node = self.model[0]\n",
    "        while node.type != NodeType.leaf:\n",
    "        \t# TODO based on the value of the record's attribute that is tested in `node`,\n",
    "        \t# set `node` to one of its child nodes until a leaf node is reached\n",
    "            print(\"test\")\n",
    "        return node.val\n",
    "    \n",
    "    def predict(self, records):\n",
    "        predictions = []\n",
    "        for record in records:\n",
    "            pred_val = apply_model(self, record)\n",
    "            # TODO append pred_val to predictions\n",
    "        return predictions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubmission(test_ids, predictions):\n",
    "    sub = pd.DataFrame()\n",
    "    sub['Id'] = test_ids\n",
    "    sub['SalePrice'] = predictions\n",
    "    sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the main function building a decision tree model, printing it and applying it on some unseen records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dt = DT()\n",
    "    print(\"Build model:\")\n",
    "    dt.build_model()\n",
    "    dt.print_model()\n",
    "\n",
    "    print(\"\\nApply model:\")\n",
    "    print(dt.apply_model([1461,20,RH,80,11622,Pave,NA,Reg,Lvl,AllPub,Inside,Gtl,NAmes,Feedr,Norm,1Fam,1Story,5,6,1961,1961,\n",
    "                          Gable,CompShg,VinylSd,VinylSd,None,0,TA,TA,CBlock,TA,TA,No,Rec,468,LwQ,144,270,882,GasA,TA,Y,\n",
    "                          SBrkr,896,0,0,896,0,0,1,0,2,1,TA,5,Typ,0,NA,Attchd,1961,Unf,1,730,TA,TA,Y,140,0,0,0,120,0,NA,\n",
    "                          MnPrv,NA,0,6,2010,WD,Normal]))\n",
    "    \n",
    "    print(dt.apply_model(['sunny', 85, 85, 'false']))\n",
    "    print(dt.apply_model(['overcast', 75, 85, 'true']))\n",
    "    print(dt.apply_model(['rain', 75, 85, 'false']))\n",
    "\n",
    "    createSubmission(test_ids, dt.predict(test_data))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
