{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk import ngrams\n",
    "#from datasketch.experimental.aio.lsh import AsyncMinHashLSH\n",
    "#from datasketch import MinHash, MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_json(\"data/assignment3_aricles.json\", orient='records', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Title</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A North Carolina woman is trying to warn other...</td>\n",
       "      <td>Facebook Friend Request Nearly Cost One North ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...</td>\n",
       "      <td>Amlin plc UK Regulatory Announcement: Total Vo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...</td>\n",
       "      <td>Khaleda asks for security</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Tikcro enters into research and license agreem...   \n",
       "1  A North Carolina woman is trying to warn other...   \n",
       "2  LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...   \n",
       "3  Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...   \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...   \n",
       "\n",
       "                                               Title  article_id  \n",
       "0  Tikcro enters into research and license agreem...           0  \n",
       "1  Facebook Friend Request Nearly Cost One North ...           1  \n",
       "2  Amlin plc UK Regulatory Announcement: Total Vo...           2  \n",
       "3                          Khaleda asks for security           3  \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Title</th>\n",
       "      <th>article_id</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>Tikcro enters into research and license agreem...</td>\n",
       "      <td>0</td>\n",
       "      <td>('Tikcro', 'enters') ('enters', 'into') ('into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A North Carolina woman is trying to warn other...</td>\n",
       "      <td>Facebook Friend Request Nearly Cost One North ...</td>\n",
       "      <td>1</td>\n",
       "      <td>('A', 'North') ('North', 'Carolina') ('Carolin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...</td>\n",
       "      <td>Amlin plc UK Regulatory Announcement: Total Vo...</td>\n",
       "      <td>2</td>\n",
       "      <td>('LONDONBUSINESS', 'WIRE\\n\\nAMLIN') ('WIRE\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...</td>\n",
       "      <td>Khaleda asks for security</td>\n",
       "      <td>3</td>\n",
       "      <td>('Khaleda', 'asks') ('asks', 'for') ('for', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>Liberian Health Clinics Reopen Slowly with Ren...</td>\n",
       "      <td>4</td>\n",
       "      <td>('Liberian', 'Health') ('Health', 'Clinics') (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Tikcro enters into research and license agreem...   \n",
       "1  A North Carolina woman is trying to warn other...   \n",
       "2  LONDON--(BUSINESS WIRE)--\\n\\nAMLIN plc\\n\\nTOTA...   \n",
       "3  Khaleda asks for security\\n\\n\\n\\nBNP Chairpers...   \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...   \n",
       "\n",
       "                                               Title  article_id  \\\n",
       "0  Tikcro enters into research and license agreem...           0   \n",
       "1  Facebook Friend Request Nearly Cost One North ...           1   \n",
       "2  Amlin plc UK Regulatory Announcement: Total Vo...           2   \n",
       "3                          Khaleda asks for security           3   \n",
       "4  Liberian Health Clinics Reopen Slowly with Ren...           4   \n",
       "\n",
       "                                              ngrams  \n",
       "0  ('Tikcro', 'enters') ('enters', 'into') ('into...  \n",
       "1  ('A', 'North') ('North', 'Carolina') ('Carolin...  \n",
       "2  ('LONDONBUSINESS', 'WIRE\\n\\nAMLIN') ('WIRE\\n\\n...  \n",
       "3  ('Khaleda', 'asks') ('asks', 'for') ('for', 's...  \n",
       "4  ('Liberian', 'Health') ('Health', 'Clinics') (...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can use n-gram at word level for this task\n",
    "#try with different n-gram values \n",
    "# You can use ngrams from nltk for this\n",
    "def getNgrams(articles):\n",
    "    n_grams = []\n",
    "    #return articles with a field ngrams\n",
    "    #articles['Content'] = articles['Content'].map(lambda x: x.lstrip(\"')(-?:/.,\").rstrip('aAbBcC'))\n",
    "    for content in articles['Content']:\n",
    "        n = 2\n",
    "        content = content.split(' ')\n",
    "        content = [x.strip().replace('-', '') for x in content]\n",
    "        content = [x.strip().replace('?', '') for x in content]\n",
    "        content = [x.strip().replace(':', '') for x in content]\n",
    "        content = [x.strip().replace('/', '') for x in content]\n",
    "        content = [x.strip().replace('.', '') for x in content]\n",
    "        content = [x.strip().replace(',', '') for x in content]\n",
    "        content = [x.strip().replace('\\\\', '') for x in content]\n",
    "        content = [x.strip().replace('(', '') for x in content]\n",
    "        content = [x.strip().replace(')', '') for x in content]\n",
    "        content = [x.strip().replace(\"'\", '') for x in content]\n",
    "        content = [x.strip().replace('\"', '') for x in content]\n",
    "        word_grams = []\n",
    "        ngram = ngrams(content,n)\n",
    "        word_grams.append(' '.join(str(i) for i in ngram))\n",
    "        tmp = word_grams[0]\n",
    "        n_grams.append(str(tmp))\n",
    "    articles['temp'] = pd.Series(n_grams) #make new field 'ngrams'. Ngrams are the different sequences of length n in articles.\n",
    "    n_grams = []\n",
    "    #return articles with a field ngrams\n",
    "    for title in articles['Title']:\n",
    "        n = 2\n",
    "        title = title.split(' ')\n",
    "        title = [x.strip().replace('-', '') for x in title]\n",
    "        title = [x.strip().replace('?', '') for x in title]\n",
    "        title = [x.strip().replace(':', '') for x in title]\n",
    "        title = [x.strip().replace('/', '') for x in title]\n",
    "        title = [x.strip().replace('.', '') for x in title]\n",
    "        title = [x.strip().replace(',', '') for x in title]\n",
    "        title = [x.strip().replace('\\\\', '') for x in title]\n",
    "        title = [x.strip().replace('(', '') for x in title]\n",
    "        title = [x.strip().replace(')', '') for x in title]\n",
    "        title = [x.strip().replace(\"'\", '') for x in title]\n",
    "        title = [x.strip().replace('\"', '') for x in title]\n",
    "        word_grams = []\n",
    "        ngram = ngrams(title,n)\n",
    "        word_grams.append(' '.join(str(i) for i in ngram))\n",
    "        tmp2 = word_grams[0]\n",
    "        n_grams.append(str(tmp2))\n",
    "    articles['temp2'] = pd.Series(n_grams) \n",
    "getNgrams(articles)\n",
    "articles['ngrams'] = articles['temp'] + articles['temp2']\n",
    "articles = articles.drop(columns=['temp', 'temp2'])\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert n-grams into binary vector representation for each document. You can do some optimzations if the matrix is too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tikcro enters\n"
     ]
    }
   ],
   "source": [
    "articles['ngrams'] = articles['ngrams'].str.lower()\n",
    "articles['ngrams'] = articles['ngrams'].str.replace(\"', '\",' ').str.split(\"'\\) \\('\")\n",
    "for i,x in enumerate(articles['ngrams']):\n",
    "    articles['ngrams'][i][0] = articles['ngrams'][i][0].replace(\"('\",'')\n",
    "    articles['ngrams'][i][len(articles['ngrams'][i])-1] = articles['ngrams'][i][len(articles['ngrams'][i])-1].replace(\"')\",'')\n",
    "print(articles.ngrams[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_ngrams = []\n",
    "#for ngrams in articles['ngrams']:\n",
    "#    unique_ngrams.append(list(set(ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48505, 3695498)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "docs = articles.index\n",
    "indptr = [0] \n",
    "indices = [] \n",
    "data = [] \n",
    "vocabulary = {} \n",
    "for d in docs:\n",
    "    unique_ngrams = list(set(articles.ngrams[d]))\n",
    "    for ngram in unique_ngrams:\n",
    "        #if ngram in uniqueShingles\n",
    "        index = vocabulary.setdefault(ngram, len(vocabulary)) \n",
    "        indices.append(index) \n",
    "        data.append(1) \n",
    "    indptr.append(len(indices))\n",
    "binaryMatrix = csr_matrix((data, indices, indptr), dtype=int)\n",
    "print(binaryMatrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a']\n"
     ]
    }
   ],
   "source": [
    "#binaryMatrixTransposed = binaryMatrix.transpose()\n",
    "#print(binaryMatrixTransposed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need hash function that maps integers 0, 1, . . . , k − 1 to bucket numbers 0 through k − 1. It might be impossible to avoid collisions but as long as the collions are too many it won't matter much.\n",
    "\n",
    "* The simplest would be using the builtin hash() function, it can be for example, hash(rownumber) % Numberofbuckets\n",
    "* You can generate several of these hash functions by xoring a random integer (hash(rownumber)^randint) % Numberofbuckets\n",
    "* It can also be a as simple as (rownumber * randint) % Numberofbuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "hashValMatrix = np.empty((binaryMatrix.shape[1], 100))\n",
    "def getHashFunctionValues(numrows, numhashfunctions):\n",
    "    #return a matrix with hash values \n",
    "    numBuckets = numrows  \n",
    "    rand_int = [random.randint(1, numrows) for i in range(0,numhashfunctions)]\n",
    "    for i in range(0,numrows):\n",
    "        hashValMatrix[i,:] = [(i^rand_int[j]) % numBuckets for j in range(numhashfunctions)] \n",
    "    return hashValMatrix\n",
    "\n",
    "hashValMatrix=getHashFunctionValues(numrows=binaryMatrix.shape[1], numhashfunctions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
      "1\n",
      "aa\n",
      "bb\n",
      "2\n",
      "aa\n",
      "bc\n",
      "3\n",
      "aa\n",
      "bd\n",
      "2\n",
      "ab\n",
      "bc\n",
      "3\n",
      "ab\n",
      "bd\n",
      "3\n",
      "ac\n",
      "bd\n"
     ]
    }
   ],
   "source": [
    "#print(hashValMatrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute minhash following the faster algorithm from the lecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a3a9aaa19a75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m sign_matrix = np.memmap('LSH.sign_matrix', dtype=np.float64, mode='w+',\n\u001b[0m\u001b[0;32m      2\u001b[0m               shape=(hashValMatrix.shape[1],binaryMatrix.shape[0]))\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#sign_matrix = np.memmap('LSH.sign_matrix', dtype=np.float64, mode='r+',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#              shape=(hashValMatrix.shape[1],binaryMatrixTransposed.shape[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msign_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "sign_matrix = np.memmap('LSH.sign_matrix', dtype=np.float64, mode='w+',\n",
    "              shape=(hashValMatrix.shape[1],binaryMatrix.shape[0]))\n",
    "#sign_matrix = np.memmap('LSH.sign_matrix', dtype=np.float64, mode='r+',\n",
    "#              shape=(hashValMatrix.shape[1],binaryMatrixTransposed.shape[0]))\n",
    "print(sign_matrix.shape)\n",
    "\n",
    "def getMinHashSignatureMatrix(binary_matrix, hash_val_matrix):\n",
    "#return minhash signature matrix \n",
    "    for row in range(binary_matrix.shape[0]):\n",
    "        #Column indices for row:\n",
    "        #print(range(binary_matrix.shape[0]))\n",
    "        #print(row)\n",
    "        ind = binary_matrix.indices[binary_matrix.indptr[row]:binary_matrix.indptr[row+1]]\n",
    "        #indices of nonzero elements in row \n",
    "        for hash_col in range(hash_val_matrix.shape[1]): \n",
    "            #add column values for row:\n",
    "            sign_matrix[hash_col,row] = min(hash_val_matrix[:,hash_col][ind]) \n",
    "    return sign_matrix\n",
    "#columns = signatures\n",
    "sign_matrix = getMinHashSignatureMatrix(binaryMatrix, hashValMatrix)\n",
    "print(sign_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash signature bands into buckets. Find a way to combine all the signature values in a band and hash them into a number of buckets ususally very high.\n",
    "* Easiest way is to add all the signature values in the bucket and use a similar hash function like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#BRUK NP HVIS FOR TREGT\n",
    "#SUBMISSION FILE COLUMNS?\n",
    "\n",
    "#1. divide signature matrix into bands of rows (divide into b parts of r rows).\n",
    "#2. for each band, map each column to a integer/bucket number. can use same hash function for all bands. buckets should be \n",
    "#unique for each band.\n",
    "#3. candidate pair: hashed to same bucket using atleast one band\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "def getLSH(signature_matrix, num_bands, num_buckets):\n",
    "    signature_matrix_transposed = np.transpose(signature_matrix) #transpose before splitting on columns\n",
    "    bands = np.hsplit(signature_matrix_transposed, num_bands) #b = 20, r = 5\n",
    "    all_buckets = [None]*num_bands\n",
    "    buckets = [None]*num_buckets\n",
    "    tempSum = [None]*signature_matrix.shape[1]\n",
    "    for i,band in enumerate(bands):\n",
    "        print(i)\n",
    "        band = np.transpose(band)\n",
    "        for article in range(band.shape[1]):\n",
    "            tempSum[article] = sum(band[:,article]) % num_buckets #can use same hash function for all bands -> no need for randint\n",
    "        tempSumIndexes = [test for test in itertools.combinations(range(len(tempSum)), 2)]\n",
    "        for a, b in enumerate(itertools.combinations(tempSum, 2)):\n",
    "            if (b[0]==b[1]) && (tempSumIndexes[a][0] not in buckets[a]) && (tempSumIndexes[a][0]!=a):\n",
    "                buckets[a].append(tempSumIndexes[a][0])\n",
    "            if (b[0]==b[1]) && (tempSumIndexes[a][1] not in buckets[a] && (tempSumIndexes[a][1]!=a)):\n",
    "                buckets[a].append(tempSumIndexes[a][1])\n",
    "        all_buckets.append(buckets)\n",
    "    final_buckets = []\n",
    "    final_buckets = zip(*all_buckets)\n",
    "    #remove duplicates in buckets:\n",
    "    for i,articles in enumerate(final_buckets):\n",
    "        final_buckets[i]=list(OrderedDict.fromkeys(final_buckets))\n",
    "    return final_buckets\n",
    "nearest_neighbours = getLSH(sign_matrix,20,48505)\n",
    "\n",
    "\n",
    "\n",
    "#for j in tempSum:\n",
    "        #    buckets[j]==[]\n",
    "        #    for idx,k in enumerate(tempSum):\n",
    "        #        if j==k and idx not in buckets[j]:\n",
    "        #            buckets[j].append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune parameters to make sure the threshold is appropriate.\n",
    "## plot the probability of two similar items falling in same bucked for different threshold values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
      "[0.0, 0.00019998100113904904, 0.0063805813047682625, 0.04749425912497118, 0.1860495521491441, 0.4700507153168765, 0.8019024538382217, 0.9747805441880405, 0.9996439421094793, 0.9999999824090121, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "num_bands = 20\n",
    "r = 5\n",
    "x_axis = [float(x/10) for x in range(0,11)]\n",
    "print(x_axis)\n",
    "y_axis = [1-(1-t**r)**num_bands for t in x_axis]\n",
    "print(y_axis)\n",
    "plt.scatter(x_axis,y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best parameters and get nearest neighbors of each articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results to submissions.csv file and get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write article ids, nearest neighbours (documents in same buckets)\n",
    "[article_ids = i for i in range(sign_matrix.shape[1])]\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "    sub['Id'] = article_ids #article IDs\n",
    "    sub['NearestNeighbours'] = nearest_neighbours\n",
    "    sub.to_csv('submission.csv',index=False)\n",
    "#DUE 18.03"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
