{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk import ngrams\n",
    "#from datasketch.experimental.aio.lsh import AsyncMinHashLSH\n",
    "#from datasketch import MinHash, MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data file couldn't be checked into github because it is too large instead it must be downloaded here #https://www.dropbox.com/s/ir6he8jxxagugnw/assignment3_aricles.json?dl=0datafile =  'data/assignment3_aricles.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_json(\"data/assignment3_aricles.json\", orient='records', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles.head()\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Title</th>\n",
       "      <th>article_id</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are you ready to go back to the Moon?  NASA to...</td>\n",
       "      <td>LAMP Educational Site</td>\n",
       "      <td>0</td>\n",
       "      <td>[('Are', 'you') ('you', 'ready') ('ready', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON - US Secretary of State Hillary Cli...</td>\n",
       "      <td>Clinton urges Egypt  Israel to talk on Sinai</td>\n",
       "      <td>1</td>\n",
       "      <td>[('WASHINGTON', '') ('', 'US') ('US', 'Secreta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The \"hurricane ride-out team\" at NASA's Kenned...</td>\n",
       "      <td>SPACE.com -- Bracing for Impact</td>\n",
       "      <td>2</td>\n",
       "      <td>[('The', '\"hurricane') ('\"hurricane', 'rideout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Search the history of over 284 billion web pag...</td>\n",
       "      <td>Internet Archive Wayback Machine</td>\n",
       "      <td>3</td>\n",
       "      <td>[('Search', 'the') ('the', 'history') ('histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Islamic State (IS) Sunni radical group ove...</td>\n",
       "      <td>IS overruns parts of Unesco-listed Syrian city</td>\n",
       "      <td>4</td>\n",
       "      <td>[('The', 'Islamic') ('Islamic', 'State') ('Sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  Are you ready to go back to the Moon?  NASA to...   \n",
       "1  WASHINGTON - US Secretary of State Hillary Cli...   \n",
       "2  The \"hurricane ride-out team\" at NASA's Kenned...   \n",
       "3  Search the history of over 284 billion web pag...   \n",
       "4  The Islamic State (IS) Sunni radical group ove...   \n",
       "\n",
       "                                            Title  article_id  \\\n",
       "0                           LAMP Educational Site           0   \n",
       "1    Clinton urges Egypt  Israel to talk on Sinai           1   \n",
       "2                 SPACE.com -- Bracing for Impact           2   \n",
       "3                Internet Archive Wayback Machine           3   \n",
       "4  IS overruns parts of Unesco-listed Syrian city           4   \n",
       "\n",
       "                                              ngrams  \n",
       "0  [('Are', 'you') ('you', 'ready') ('ready', 'to...  \n",
       "1  [('WASHINGTON', '') ('', 'US') ('US', 'Secreta...  \n",
       "2  [('The', '\"hurricane') ('\"hurricane', 'rideout...  \n",
       "3  [('Search', 'the') ('the', 'history') ('histor...  \n",
       "4  [('The', 'Islamic') ('Islamic', 'State') ('Sta...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can use n-gram at word level for this task\n",
    "#try with different n-gram values \n",
    "# You can use ngrams from nltk for this\n",
    "def getNgrams(articles):\n",
    "    n_grams = []\n",
    "    #return articles with a field ngrams\n",
    "    for content in articles['Content']:\n",
    "        n = 2\n",
    "        content = content.split(' ')\n",
    "        content = [x.strip().replace('-', '') for x in content]\n",
    "        content = [x.strip().replace('?', '') for x in content]\n",
    "        content = [x.strip().replace(':', '') for x in content]\n",
    "        content = [x.strip().replace('/', '') for x in content]\n",
    "        content = [x.strip().replace('.', '') for x in content]\n",
    "        content = [x.strip().replace(',', '') for x in content]\n",
    "        word_grams = []\n",
    "        ngram = ngrams(content,n)\n",
    "        word_grams.append(' '.join(str(i) for i in ngram))\n",
    "        n_grams.append(word_grams)\n",
    "    articles['temp'] = pd.Series(n_grams) #make new field 'ngrams'. Ngrams are the different sequences of length n in articles.\n",
    "    n_grams = []\n",
    "    #return articles with a field ngrams\n",
    "    for title in articles['Title']:\n",
    "        n = 2\n",
    "        title = title.split(' ')\n",
    "        title = [x.strip().replace('-', '') for x in title]\n",
    "        title = [x.strip().replace('?', '') for x in title]\n",
    "        title = [x.strip().replace(':', '') for x in title]\n",
    "        title = [x.strip().replace('/', '') for x in title]\n",
    "        title = [x.strip().replace('.', '') for x in title]\n",
    "        title = [x.strip().replace(',', '') for x in title]\n",
    "        word_grams = []\n",
    "        ngram = ngrams(title,n)\n",
    "        word_grams.append(' '.join(str(i) for i in ngram))\n",
    "        n_grams.append(word_grams)\n",
    "    articles['temp2'] = pd.Series(n_grams) \n",
    "getNgrams(articles)\n",
    "articles['ngrams'] = articles['temp'] + articles['temp2']\n",
    "articles = articles.drop(columns=['temp', 'temp2'])\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert n-grams into binary vector representation for each document. You can do some optimzations if the matrix is too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryMatrix(articles):\n",
    "    #return binary matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need hash function that maps integers 0, 1, . . . , k − 1 to bucket numbers 0 through k − 1. It might be impossible to avoid collisions but as long as the collions are too many it won't matter much.\n",
    "\n",
    "* The simplest would be using the builtin hash() function, it can be for example, hash(rownumber) % Numberofbuckets\n",
    "* You can generate several of these hash functions by xoring a random integer (hash(rownumber)^randint) % Numberofbuckets\n",
    "* It can also be a as simple as (rownumber * randint) % Numberofbuckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHashFunctionValues(numrows, numhashfunctions):\n",
    "    #return a matrix with hash values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute minhash following the faster algorithm from the lecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinHashSignatureMatrix(binary_matrix, hash_val_matrix)\n",
    "    #return minhash signature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash signature bands into buckets. Find a way to combine all the signature values in a band and hash them into a number of buckets ususally very high.\n",
    "* Easiest way is to add all the signature values in the bucket and use a similar hash function like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLSH(signature_matrix, hashfunctions, num_bands, num_buckets):\n",
    "   #return lsh buckets or hash table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune parameters to make sure the threshold is appropriate.\n",
    "## plot the probability of two similar items falling in same bucked for different threshold values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best parameters and get nearest neighbors of each articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results to submissions.csv file and get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
